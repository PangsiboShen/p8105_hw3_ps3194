---
title: "p8105_hw3_ps3194"
author: "Pangsibo Shen"
date: "10/9/2020"
output:
  html_document:
    keep_md: true
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)
library(plotly)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

```{r}
data("instacart")
```

###### how many aisles, and which are most items from?

```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```

There are 134 aisles, the the fresh vegetables aisle is the most items from. 

###### Let's make a plot

```{r}
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```
###### Let's make a table!
```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients","dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

###### Apples vs ice cream.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarise(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

###### load and tidy the data
```{r accel}
accel = read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>%
  transform(
    minute = as.numeric(minute),
    #day = as_factor(day),
    week = as.factor(week)
  ) %>%
  mutate(weekday = case_when(
    day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~ "weekday",
    day %in% c("Saturday","Sunday") ~ "weekend")
  ) %>%
  transform(
    weekday = as.factor(weekday)
  )
 

head(accel)

```

The resulting dataset has 6 variables: week, day_id, day, minute, activity_count and weekday. The weekday variable has two levels: weekday and weekend. There are `r nrow(accel)` observations from the dataset.

###### relevel the day variable to chronological order
```{r relevel}
accel$day = factor(accel$day, c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
```

###### create a table showing the sum count for each day
```{r table}
accel %>%
  group_by(week, day_id, day) %>%
  summarise(
    sum_count = sum(activity_count)
  ) %>%
  arrange(week,day) %>%
  knitr::kable(align = 'c')
```
For the first weeks, the patient's daily total activity counts generally had increased from Monday to Sunday.For week 4, the patient's daily total activity counts had decreased from Monday to Saturday. For week 5, the patient's daily total activity counts had increased from Monday to Friday.

##### wrangling the date for the plot
```{r}
accel = accel %>%
  mutate(hour = case_when(
    minute %in% 1:60 ~ 1,
    minute %in% 61:120 ~ 2,
    minute %in% 121:180 ~ 3,
    minute %in% 181:240 ~ 4,
    minute %in% 241:300 ~ 5,
    minute %in% 301:360 ~ 6,
    minute %in% 361:420 ~ 7,
    minute %in% 421:480 ~ 8,
    minute %in% 481:540 ~ 9,
    minute %in% 541:600 ~ 10,
    minute %in% 601:660 ~ 11,
    minute %in% 661:720 ~ 12,
    minute %in% 721:780 ~ 13,
    minute %in% 781:840 ~ 14,
    minute %in% 841:900 ~ 15,
    minute %in% 901:960 ~ 16,
    minute %in% 961:1020 ~ 17,
    minute %in% 1021:1080 ~ 18,
    minute %in% 1081:1140 ~ 19,
    minute %in% 1141:1200 ~ 20,
    minute %in% 1201:1260 ~ 21,
    minute %in% 1261:1320 ~ 22,
    minute %in% 1321:1380 ~ 23,
    minute %in% 1381:1440 ~ 24,
    )) %>%
  group_by(week, day_id, day, hour) %>%
  summarise(
    hour_count = sum(activity_count)
  )

```
###### plot showing 24 hour activity
```{r}
accel %>%
  group_by(day, hour) %>%
  summarise(avg_hour_count = mean(hour_count)) %>%
  ggplot(aes(x = hour, y = avg_hour_count, color = day)) +
  geom_line(alpha = 10) +
  scale_x_continuous(breaks = accel$hour) + 
  ylab("avg hourly activity count by weeks") +
  ggtitle("24 Hour Activity") +
  guides(fill = guide_legend(title = "Week"))
```
This is a graph showing the 5 weeks average 24-hour activity count for each day in the week. From the graph, we noticed that the patient started to become active around 7 am (the patient wakes up). The activity count peaks around 13 pm and 21 pm and the peaks might be explained by exercising activities such as walking after lunch and before bed.   


## Problem 3

###### load dataset
```{r}
data("ny_noaa")
```

###### data cleaning and separate the date
```{r}
ny_noaa_tidy = ny_noaa %>%
  na.omit() %>%
  separate(date,
           c("year","month","day"),
           sep = "-") %>%
  transform(
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin),
    snow = as.character(snow)
  ) %>%
  mutate(
   prcp = prcp/10,
   tmax = tmax/10,
   tmin = tmin/10
  )

head(ny_noaa_tidy)
```
######  the most commonly observed values for snowfall
```{r}
ny_noaa_tidy %>%
  count(snow) %>%
  arrange(desc(n)) %>%
  head()
```
Other than days without snow (snowfall is 0), the most commonly observed value for snowfall is 25 mm.
 
```{r ggplot}
ny_noaa_tidy_fig = ny_noaa_tidy %>%
  filter(month %in% c("01","07")) %>%
  mutate(month = recode(month, "01" = "January", "07" = "July")) %>%
  group_by(id, year, month) %>%
  summarise(mean_tmax = mean(tmax)) %>%
  ggplot(aes(x = year, y = mean_tmax, group = id)) +
  geom_point(aes(color = id), show.legend = F) +
  theme(axis.text.x = element_text(angle = 70, vjust = 0.5, hjust = 0.5)) +
  theme(axis.title.x = element_text(margin = margin(0,0,0,0))) +
  facet_grid(cols = vars(month))

ny_noaa_tidy_fig
```
From the graph, we can see the average max temperature for those weather stations across years. The average max temperature in July is significantly higher than that in January. Also, the variation for average max temperature in January is larger than that in July. I don't see a particular trend that indicates global warming from the figure. On the other hand, there are too many lines overlaid with each other due to the large amount of Weather station ID. Hence ggplot is not very informative to show the which particular stations having extreme temperatures than others across years (outliers). In order to address this problem, a ggplotly() is used. 

```{r plotly}
ggplotly(
  ny_noaa_tidy %>%
  filter(month %in% c("01","07")) %>%
  mutate(month = recode(month, "01" = "January", "07" = "July")) %>%
  group_by(id, year, month) %>%
  summarise(mean_tmax = mean(tmax)) %>%
  ggplot(aes(x = year, y = mean_tmax, group = id)) +
  geom_point(aes(color = id)) +
  geom_path(aes(color = id), alpha = 0.2) +
  theme(axis.text.x = element_text(angle = 50, vjust = 0.5, hjust = 1)) +
  theme(axis.title.x = element_text(margin = margin(10,0,0,0))) +
  facet_grid(cols = vars(month))
)
```
From the plotly figure, we can capture several outliers: one outlier point which in July 1988, station USC00308962 had a average max temperature of 14 degree Celsius which was significantly lower than the mean_tmax of any other stations; another outlier point which in 1982 January, station USC00303889 had a average max temperature of -16.7 degree Celsius which was significantly lower than the mean_tmax of any other stations; another outlier point which in January 1996, station USC00309389 had a average max temperature of -16.1 degree Celsius which was significantly lower than the mean_tmax of any other stations.

###### Make a two-panel plot showing tmax vs tmin for the full dataset and showing the distribution of snowfall values greater than 0 and less than 100 separately by year

```{r violin}
tmax_min_fig = ny_noaa_tidy %>%
  ggplot(aes(x = tmin, y = tmax)) +
  geom_bin2d() +
  ggtitle("max vs min temperature density") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5))

ny_noaa_snow = ny_noaa_tidy %>%
  transform(snow = as.numeric(snow)) %>%
  filter(snow > 0 & snow < 100) %>%
  ggplot(aes(x = year, y = snow, fill = year)) +
  geom_violin() +
  ggtitle("snowfall density") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5))

ggpubr::ggarrange(tmax_min_fig, ny_noaa_snow, ncol = 2, nrow = 1)
```
